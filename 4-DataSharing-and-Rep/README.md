Replication and Data Sharing Activities
============================
by Eva Vivalt

There are several activities you can do to work on writing replicable code:

Conceptual Replication:

1. Read the major pyschology and economics replications papers in *Science*, the technical comment, and the reply. All are linked [here](http://datacolada.org/47). You may also find Brian Nosek and Elizabeth Gilbert's [blog description](http://retractionwatch.com/2016/03/07/lets-not-mischaracterize-replication-studies-authors/) of the differences between one specific original study and its replication interesting. What term from Michael Clemens' replication taxonomy do you think best applies to this research? Where do you come down as to whether the experiments were similar enough to be considered replications?

Empirical Replication:

1. If participating in our "many analyses" project, try writing replicable code to implement the analyses in your PAP! The data will be made publicly available in the course of the workshop (after pre-analyses plans are written!).

2. If you prefer, you can download the data from the "crowdsourcing paper" ("Many analysts, one dataset: Making transparent how variations in analytical choices affect results" by Raphael Silberzahn and many others.) The data and materials are on [the OSF](https://osf.io/gvm2z/). You could either try and replicate (in the pure verification sense) Garret Christensen's small contribution by using [his Stata code](https://osf.io/kx3q9/), or you could continue in the spirit of the project and see if you get different results by starting your own analysis from scratch.

3. R users can easily attempt to replicate a paper on the causes of the housing crisis: "[The Subprime Crisis: Is Government Housing Policy to Blame?](https://osf.io/h9rcu/)" by Avery and Brevoort. It might be interesting to see how easy it is for you to find the data and code on your own (Is it linked or even mentioned in the paper? Is there any way you would know it was available if I didn't tell you?) but if you want a direct link, go [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/28521).

4. Stata users can attempt to replicate Casey, Glennerster, and Miguel's "[Reshaping Institutions: Evidence on Aid Impacts Using a Preanalysis Plan](http://emiguel.econ.berkeley.edu/research/reshaping-institutions-evidence-on-aid-impacts-using-a-preanalysis-plan)". The data is [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl%3A1902.1/21708).

For data sharing:

5. Once you are finished, share what you've done by uploading your code to a repository. If you are participating in our "many analyses" project, share your code to your sub-folder on OSF. Otherwise, you could try Harvard's [Dataverse](http://dataverse.harvard.edu), [OpenICPSR](http://OpenICPSR.org), [Dryad](http://datadryad.org), [Figshare](http://figshare.com), or search [re3data](http://re3data.org) to find the most appropriate place for your type of research. If you use Dataverse or Figshare, once you've posted data you can create an OSF page for your replication and link that repository to the Open Science Framework. Remember: repositories can be permanent and deliberately have no delete option, so you might not want to go all the way.
